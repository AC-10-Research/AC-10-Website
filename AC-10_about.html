<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        From Code to Chords: Unleashing AI in Music
    </title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>
            AC-10 From Code to Chords: Unleashing AI in Music
        </h1>
        <img src="robomusic.png" alt="Team Logo" class="logo-left" />
        <img src="robomusic.png" alt="Team Logo" class="logo-right" />
    </header>
    <nav>
        <a href="index.html">Home</a>
        <a href="AC-10_about.html">About</a>
        <a href="AC-10_presentation.html">Presentation</a>
    </nav>
    <main>
        <h2>Overview</h2>
        <p>
            As many of you know, AI is a machine simulation of human intelligence. It uses neural networks to learn and think. When “really” it's just doing computational attempts to minimize cost. Digital Music Processing is a software that allows you to record, edit, and produce audio that can also use virtual instruments to play MIDI files.
            When a human there are many ways to learn music, but the two most common approaches are Song Repetition and Pattern Recognition. This project will research how each learning approach affects music creation by AI. The exciting thing about this project is that neural networks can be “taught” in a similar way. With more neurons, the network can be trained on a dataset through memorization. With less, they can be trained in musical patterns. Once we have our data we’ll evaluate how the models trained on each approach compare to each other. We’ll be looking for and judging these models on several metrics like efficiency and creativity.
        </p>
        <br/>
        <p>'Link to Final Report'</p>
        <br/>
        <h2>Github</h2>
        <p>https://github.com/AC-10-Research</p>
    </main>
    <footer>
    </footer>
</body>
</html>
